{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "fceab068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from transformers import AutoFeatureExtractor, AutoModelForImageClassification\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.nn.utils.prune as prune\n",
    "import copy\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.sparse import csc_matrix, csr_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "2a2f7a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\NEW_MACHINE\\Programs\\Anaconda\\envs\\Model_Compression\\Lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "path_to_model = \"weights/my_model\"\n",
    "\n",
    "extractor = AutoFeatureExtractor.from_pretrained(path_to_model)\n",
    "vit_model = AutoModelForImageClassification.from_pretrained(path_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "792f3c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_use(model, img):\n",
    "    with torch.no_grad():\n",
    "        logits = model(**img).logits\n",
    "\n",
    "    predicted_label = logits.argmax(-1).item()\n",
    "\n",
    "    return model.config.id2label[predicted_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6adb4291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для кластеризации весов. \n",
    "def apply_weight_clusterization(module_list, bits=2):\n",
    "    \"\"\"\n",
    "    Applies weight sharing to the given model\n",
    "    \"\"\"\n",
    "    for module in module_list:\n",
    "        \n",
    "        weight = module.weight.data.cpu().numpy()\n",
    "        shape = weight.shape\n",
    "                \n",
    "        if len(shape) == 4:\n",
    "            weight = np.reshape(weight, (shape[0], shape[1]*shape[2]*shape[3]))\n",
    "            \n",
    "        print(\"Веса до кластеризации\")    \n",
    "        print(weight)\n",
    "        print()\n",
    "        mat = csr_matrix(weight)\n",
    "        min_ = min(mat.data)\n",
    "        max_ = max(mat.data)\n",
    "\n",
    "        space = np.linspace(min_, max_, num=2**bits)\n",
    "\n",
    "        kmeans = KMeans(n_clusters=len(space), init=space.reshape(-1,1), n_init= 1, algorithm=\"lloyd\")\n",
    "        \n",
    "        kmeans.fit(mat.data.reshape(-1,1))\n",
    "        new_weight = kmeans.cluster_centers_[kmeans.labels_].reshape(-1)\n",
    "        mat.data = new_weight\n",
    "             \n",
    "        module.weight.data = torch.from_numpy(mat.toarray())\n",
    "        \n",
    "        print(\"Веса после кластеризации\")\n",
    "        print(module.weight.data, module.weight.data.shape)\n",
    "        module.weight.data = torch.reshape(module.weight.data, shape)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "6e6f626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/\"\n",
    "images_list = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "4e437c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для замера размера модели.\n",
    "def size_measurement(model):\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "    size_all_mb = (param_size + buffer_size) / (1024 ** 2)\n",
    "    print('model size: {:.3f}MB'.format(size_all_mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "d52bed3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 327.302MB\n"
     ]
    }
   ],
   "source": [
    "# Найдем исходный размер модели.\n",
    "size_measurement(vit_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "0893ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_to_clusterization = []\n",
    "\n",
    "vit_model_copy = copy.deepcopy(vit_model)\n",
    "parameters_to_clusterization.append(vit_model_copy.vit.embeddings.patch_embeddings.projection)\n",
    "parameters_to_clusterization.append(vit_model_copy.vit.layernorm)\n",
    "parameters_to_clusterization.append(vit_model_copy.classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "7d33d95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16)), LayerNorm((768,), eps=1e-12, elementwise_affine=True), Linear(in_features=768, out_features=2, bias=True)]\n"
     ]
    }
   ],
   "source": [
    "print(parameters_to_clusterization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "e6eb80fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Веса до кластеризации\n",
      "[[ 0.01599822  0.05142277  0.05571121 ... -0.08067208 -0.05774073\n",
      "  -0.03657478]\n",
      " [-0.02955145  0.02847983  0.02802685 ...  0.02751332 -0.03092413\n",
      "  -0.04187002]\n",
      " [-0.0159509  -0.00071795 -0.01075949 ...  0.00088374  0.00579313\n",
      "   0.00175963]\n",
      " ...\n",
      " [-0.0403337   0.01777354  0.06060625 ... -0.02783299 -0.03638085\n",
      "  -0.04375472]\n",
      " [ 0.06298763  0.07997435  0.08153521 ... -0.0289927  -0.00268504\n",
      "  -0.04663738]\n",
      " [-0.01337854 -0.00126218  0.00302414 ... -0.00116881 -0.0155547\n",
      "  -0.00858315]]\n",
      "\n",
      "Веса после кластеризации\n",
      "tensor([[ 0.0155,  0.0851,  0.0851,  ..., -0.0953, -0.0259, -0.0259],\n",
      "        [-0.0259,  0.0155,  0.0155,  ...,  0.0155, -0.0259, -0.0259],\n",
      "        [-0.0259,  0.0155, -0.0259,  ...,  0.0155,  0.0155,  0.0155],\n",
      "        ...,\n",
      "        [-0.0259,  0.0155,  0.0851,  ..., -0.0259, -0.0259, -0.0259],\n",
      "        [ 0.0851,  0.0851,  0.0851,  ..., -0.0259,  0.0155, -0.0259],\n",
      "        [-0.0259,  0.0155,  0.0155,  ...,  0.0155, -0.0259, -0.0259]]) torch.Size([768, 768])\n",
      "Веса до кластеризации\n",
      "[0.2131897  0.21343943 0.19865169 0.20690416 0.2032685  0.21302988\n",
      " 0.21839388 0.21265182 0.21146302 0.2257917  0.2110421  0.19467002\n",
      " 0.22008918 0.21177223 0.21412602 0.20721751 0.2145798  0.20888172\n",
      " 0.21188648 0.20693986 0.21948092 0.20425431 0.21899016 0.20985085\n",
      " 0.20638621 0.200989   0.21773346 0.20689173 0.24058396 0.22542004\n",
      " 0.21777226 0.20743668 0.22263384 0.20536776 0.21942241 0.24632774\n",
      " 0.19952469 0.20192073 0.22848324 0.20176819 0.21027704 0.21051924\n",
      " 0.19946264 0.20646204 0.20638227 0.19907467 0.19332258 0.20971796\n",
      " 0.21086463 0.20583439 0.20884624 0.22923283 0.21054299 0.20743445\n",
      " 0.195684   0.21748367 0.22029284 0.21806152 0.20883726 0.21252504\n",
      " 0.21197197 0.20061666 0.21467215 0.21084116 0.20914777 0.20511222\n",
      " 0.2071712  0.22113927 0.2169242  0.21207058 0.20946513 0.21607506\n",
      " 0.20223731 0.20975155 0.20614296 0.20649548 0.20999667 0.21845034\n",
      " 0.20562372 0.23504831 0.20839153 0.2062341  0.21518846 0.19667089\n",
      " 0.20875773 0.21302569 0.0298091  0.21082343 0.20723309 0.20386077\n",
      " 0.21049361 0.21420076 0.20430778 0.20402329 0.21634954 0.21389115\n",
      " 0.21305671 0.21318062 0.20729369 0.20884605 0.20030478 0.22274351\n",
      " 0.20389391 0.20747806 0.20418927 0.2067455  0.20965537 0.21225247\n",
      " 0.23263882 0.21049464 0.20651099 0.21660183 0.22635782 0.20439656\n",
      " 0.21701652 0.205717   0.20421779 0.2119844  0.21729387 0.20960271\n",
      " 0.20606229 0.20098972 0.21165822 0.20928839 0.20697387 0.19992909\n",
      " 0.20839259 0.20145637 0.2182661  0.21759173 0.21333095 0.2243144\n",
      " 0.208055   0.19113442 0.20472144 0.21814065 0.21434075 0.20141391\n",
      " 0.20531125 0.20184414 0.20139614 0.21812399 0.20763633 0.20524463\n",
      " 0.22742946 0.19786638 0.2148855  0.20423427 0.21417777 0.20966199\n",
      " 0.20222123 0.20863913 0.2134968  0.21837087 0.20249029 0.21163523\n",
      " 0.19992146 0.21373075 0.21217856 0.21302988 0.21387252 0.20912246\n",
      " 0.20634101 0.21276917 0.20602469 0.22911674 0.21613446 0.2037347\n",
      " 0.21430476 0.20877174 0.22131231 0.2009458  0.21745159 0.20460267\n",
      " 0.21860294 0.21365656 0.21379405 0.22577989 0.19666587 0.2073006\n",
      " 0.21516083 0.21117021 0.21651964 0.2192406  0.21882442 0.21323404\n",
      " 0.20315148 0.05396432 0.20817636 0.21485291 0.20707051 0.21646143\n",
      " 0.21386947 0.2075398  0.20740399 0.21935864 0.22149605 0.20977843\n",
      " 0.20994411 0.21038467 0.20629136 0.20675285 0.21879475 0.21254048\n",
      " 0.19864778 0.20648669 0.21491896 0.21657154 0.20480113 0.20691417\n",
      " 0.20749798 0.21630576 0.2176985  0.23204105 0.20533222 0.21776797\n",
      " 0.19957086 0.21035069 0.20335662 0.21839888 0.2111876  0.20760272\n",
      " 0.21988428 0.21776077 0.21525995 0.2072695  0.21786164 0.20762658\n",
      " 0.20950958 0.20894396 0.20696935 0.22327672 0.20747992 0.21301357\n",
      " 0.22110765 0.20394903 0.2039785  0.22613731 0.22180998 0.20289005\n",
      " 0.1905619  0.19955957 0.20887475 0.20997956 0.21628237 0.21773827\n",
      " 0.2183796  0.21173188 0.21180744 0.20935522 0.21787068 0.2031891\n",
      " 0.21042474 0.22353727 0.21988018 0.21705943 0.20817998 0.21225174\n",
      " 0.2110176  0.22276244 0.20680204 0.20730312 0.20789893 0.2084787\n",
      " 0.21113758 0.22352028 0.21842651 0.20487009 0.2116507  0.21028426\n",
      " 0.21311761 0.21258996 0.21416631 0.22227776 0.21878126 0.20355684\n",
      " 0.21817559 0.22405681 0.20629948 0.2116494  0.2035748  0.21570106\n",
      " 0.2106307  0.20761985 0.21491142 0.21566562 0.21876413 0.20987436\n",
      " 0.23158503 0.21475336 0.21751443 0.22453009 0.19857962 0.20650582\n",
      " 0.20024301 0.20648354 0.21670032 0.2072714  0.20064388 0.20763405\n",
      " 0.21459784 0.2136811  0.20530587 0.20337924 0.20329414 0.21484521\n",
      " 0.21509632 0.19588754 0.19972992 0.2117339  0.20302342 0.21265739\n",
      " 0.21130164 0.22255594 0.21158613 0.21011293 0.01530443 0.21606651\n",
      " 0.1965416  0.19447343 0.21739945 0.20058483 0.19782323 0.20380542\n",
      " 0.20615843 0.20634095 0.20348091 0.20600763 0.21306995 0.21494922\n",
      " 0.21529597 0.19407544 0.19989954 0.20536274 0.21656393 0.21301006\n",
      " 0.21669945 0.20752402 0.21025285 0.21222712 0.21367764 0.20676234\n",
      " 0.18314137 0.210706   0.21122932 0.20726992 0.2041761  0.22347753\n",
      " 0.20739473 0.2100962  0.20963567 0.21872216 0.20526148 0.21539052\n",
      " 0.21470489 0.2094247  0.20947507 0.21005252 0.23899586 0.20908946\n",
      " 0.21752238 0.20150371 0.21180159 0.21009707 0.2192033  0.2065537\n",
      " 0.21290052 0.20788825 0.20691904 0.20549019 0.21162334 0.21347323\n",
      " 0.20805906 0.20814015 0.20229264 0.21664    0.20452827 0.23092233\n",
      " 0.21507366 0.21463801 0.20262803 0.22055347 0.01767445 0.21624132\n",
      " 0.20695709 0.20455456 0.19718827 0.23420186 0.20884399 0.21871181\n",
      " 0.20576648 0.21151958 0.20277727 0.19908862 0.22366278 0.21918711\n",
      " 0.22105743 0.22274747 0.21387239 0.20461111 0.20186584 0.20020989\n",
      " 0.19955376 0.2165428  0.21514173 0.20965673 0.20737295 0.20542707\n",
      " 0.2131558  0.20439225 0.19804189 0.20133829 0.23011978 0.20356762\n",
      " 0.21363716 0.2068984  0.09034427 0.21914102 0.19729611 0.2171606\n",
      " 0.20470186 0.22640572 0.21159394 0.20441973 0.21808302 0.20596845\n",
      " 0.20726623 0.21047068 0.20393065 0.21701667 0.21237406 0.20819904\n",
      " 0.20538181 0.21517555 0.21278173 0.21908341 0.20932345 0.2105633\n",
      " 0.21264906 0.20991872 0.20748954 0.21945913 0.21442519 0.20330496\n",
      " 0.2118199  0.22344649 0.20828429 0.20385396 0.25627646 0.22066908\n",
      " 0.2037875  0.21133466 0.20516506 0.21693629 0.20038594 0.22055383\n",
      " 0.20675464 0.20482579 0.21487433 0.21627659 0.20546693 0.20407423\n",
      " 0.21667655 0.21098118 0.20607907 0.20958531 0.21600333 0.22475195\n",
      " 0.20236577 0.19199994 0.20485026 0.19400385 0.20030616 0.20864588\n",
      " 0.21289653 0.21987589 0.2145689  0.21265233 0.20623533 0.20140482\n",
      " 0.21376406 0.2058744  0.21015307 0.22389004 0.20226954 0.22338973\n",
      " 0.20566826 0.2060837  0.20836096 0.20881225 0.21667121 0.21095926\n",
      " 0.21488641 0.20871049 0.20879355 0.20970565 0.22076614 0.20769879\n",
      " 0.21691163 0.21826164 0.21847819 0.21000282 0.2124755  0.22093268\n",
      " 0.2180489  0.2056293  0.20501967 0.21844955 0.20757137 0.22851801\n",
      " 0.199948   0.20372519 0.2394864  0.211171   0.20542873 0.21384107\n",
      " 0.21219367 0.21868001 0.21227615 0.21577917 0.21333487 0.2117366\n",
      " 0.21418327 0.21177848 0.20100093 0.20464861 0.20578633 0.20266037\n",
      " 0.20323287 0.21666162 0.20299159 0.20493986 0.21983257 0.20822781\n",
      " 0.20884927 0.07546306 0.21821761 0.21020973 0.20420058 0.2085453\n",
      " 0.20775774 0.20929018 0.20433432 0.21110654 0.20636068 0.21426122\n",
      " 0.21079242 0.20613553 0.19863994 0.2125708  0.21995169 0.20993786\n",
      " 0.21778236 0.20057292 0.21586941 0.20352302 0.21220219 0.21147737\n",
      " 0.21046841 0.19851829 0.2271664  0.21035667 0.21130206 0.2200904\n",
      " 0.20961164 0.20870595 0.20297493 0.2010714  0.20800366 0.21955952\n",
      " 0.2016664  0.20316918 0.21061517 0.21668923 0.2132078  0.21857068\n",
      " 0.19807048 0.20766936 0.21525407 0.21130806 0.20906623 0.2202352\n",
      " 0.21142988 0.20453349 0.20687452 0.20925942 0.2349156  0.20280816\n",
      " 0.21117717 0.19529091 0.21284395 0.20239095 0.21677579 0.20977743\n",
      " 0.21187092 0.2113979  0.20703815 0.21399513 0.20400497 0.21506268\n",
      " 0.20479485 0.21119131 0.2123158  0.21241525 0.22702834 0.2137394\n",
      " 0.21125945 0.20990905 0.22293462 0.21682538 0.21367373 0.2106736\n",
      " 0.21779405 0.21870281 0.20939142 0.21760195 0.2146567  0.19815412\n",
      " 0.21793817 0.24086186 0.20520155 0.21106182 0.21751298 0.19815812\n",
      " 0.19878778 0.21050358 0.20781225 0.2149615  0.20593028 0.21282905\n",
      " 0.2120678  0.21303324 0.21989408 0.20770012 0.19660608 0.21639472\n",
      " 0.21366102 0.2520273  0.20898339 0.20556185 0.19612761 0.22584909\n",
      " 0.20896776 0.20937525 0.20488222 0.2072665  0.24016173 0.20026046\n",
      " 0.20552462 0.2054504  0.19506554 0.20575447 0.2063429  0.22270887\n",
      " 0.20336655 0.21218202 0.21065155 0.20807315 0.20397416 0.20752685\n",
      " 0.21784188 0.22548859 0.21030961 0.20847207 0.21423653 0.21727227\n",
      " 0.21253763 0.20754682 0.21287376 0.20891754 0.07114636 0.21728742\n",
      " 0.21218069 0.2119026  0.2069511  0.221079   0.21723577 0.2119929\n",
      " 0.01897926 0.21326517 0.21108177 0.20883259 0.21947725 0.20132329\n",
      " 0.21291205 0.20543325 0.24548233 0.1937739  0.20079106 0.22205459\n",
      " 0.21092626 0.2103654  0.20851251 0.21811457 0.21424486 0.2119254\n",
      " 0.210776   0.20957462 0.20247002 0.21499428 0.21338128 0.20450267\n",
      " 0.20624672 0.20215973 0.2102253  0.21090247 0.21359876 0.22075799\n",
      " 0.19982801 0.2064869  0.19414428 0.2058372  0.20533314 0.21076888\n",
      " 0.23037179 0.21794121 0.21651283 0.22102384 0.21350244 0.2098005\n",
      " 0.21143201 0.20488413 0.21541563 0.20891844 0.20740733 0.216347\n",
      " 0.21716757 0.20524898 0.20339221 0.20591003 0.20812535 0.20431168\n",
      " 0.22786309 0.20742257 0.21728423 0.21327716 0.20966648 0.19730856\n",
      " 0.22297622 0.20639706 0.21361908 0.20028554 0.20633332 0.21239452\n",
      " 0.19768456 0.20094313 0.21224202 0.21853662 0.2109043  0.21944779\n",
      " 0.21143335 0.21563677 0.21108298 0.22074936 0.2311349  0.20023641\n",
      " 0.20312981 0.21908318 0.20982444 0.02815665 0.20327212 0.21148433\n",
      " 0.20058534 0.21261074 0.21326514 0.2102795  0.22039093 0.22215831]\n",
      "\n",
      "Веса после кластеризации\n",
      "tensor([[0.2192, 0.2192, 0.2063, 0.2063, 0.2063, 0.2192, 0.2192, 0.2063, 0.2063,\n",
      "         0.2192, 0.2063, 0.2063, 0.2192, 0.2063, 0.2192, 0.2063, 0.2192, 0.2063,\n",
      "         0.2063, 0.2063, 0.2192, 0.2063, 0.2192, 0.2063, 0.2063, 0.2063, 0.2192,\n",
      "         0.2063, 0.2192, 0.2192, 0.2192, 0.2063, 0.2192, 0.2063, 0.2192, 0.2192,\n",
      "         0.2063, 0.2063, 0.2192, 0.2063, 0.2063, 0.2063, 0.2063, 0.2063, 0.2063,\n",
      "         0.2063, 0.2063, 0.2063, 0.2063, 0.2063, 0.2063, 0.2192, 0.2063, 0.2063,\n",
      "         0.2063, 0.2192, 0.2192, 0.2192, 0.2063, 0.2063, 0.2063, 0.2063, 0.2192,\n",
      "         0.2063, 0.2063, 0.2063, 0.2063, 0.2192, 0.2192, 0.2063, 0.2063, 0.2192,\n",
      "         0.2063, 0.2063, 0.2063, 0.2063, 0.2063, 0.2192, 0.2063, 0.2192, 0.2063,\n",
      "         0.2063, 0.2192, 0.2063, 0.2063, 0.2192, 0.0220, 0.2063, 0.2063, 0.2063,\n",
      "         0.2063, 0.2192, 0.2063, 0.2063, 0.2192, 0.2192, 0.2192, 0.2192, 0.2063,\n",
      "         0.2063, 0.2063, 0.2192, 0.2063, 0.2063, 0.2063, 0.2063, 0.2063, 0.2063,\n",
      "         0.2192, 0.2063, 0.2063, 0.2192, 0.2192, 0.2063, 0.2192, 0.2063, 0.2063,\n",
      "         0.2063, 0.2192, 0.2063, 0.2063, 0.2063, 0.2063, 0.2063, 0.2063, 0.2063,\n",
      "         0.2063, 0.2063, 0.2192, 0.2192, 0.2192, 0.2192, 0.2063, 0.2063, 0.2063,\n",
      "         0.2192, 0.2192, 0.2063, 0.2063, 0.2063, 0.2063, 0.2192, 0.2063, 0.2063,\n",
      "         0.2192, 0.2063, 0.2192, 0.2063, 0.2192, 0.2063, 0.2063, 0.2063, 0.2192,\n",
      "         0.2192, 0.2063, 0.2063, 0.2063, 0.2192, 0.2063, 0.2192, 0.2192, 0.2063,\n",
      "         0.2063, 0.2192, 0.2063, 0.2192, 0.2192, 0.2063, 0.2192, 0.2063, 0.2192,\n",
      "         0.2063, 0.2192, 0.2063, 0.2192, 0.2192, 0.2192, 0.2192, 0.2063, 0.2063,\n",
      "         0.2192, 0.2063, 0.2192, 0.2192, 0.2192, 0.2192, 0.2063, 0.0727, 0.2063,\n",
      "         0.2192, 0.2063, 0.2192, 0.2192, 0.2063, 0.2063, 0.2192, 0.2192, 0.2063,\n",
      "         0.2063, 0.2063, 0.2063, 0.2063, 0.2192, 0.2063, 0.2063, 0.2063, 0.2192,\n",
      "         0.2192, 0.2063, 0.2063, 0.2063, 0.2192, 0.2192, 0.2192, 0.2063, 0.2192,\n",
      "         0.2063, 0.2063, 0.2063, 0.2192, 0.2063, 0.2063, 0.2192, 0.2192, 0.2192,\n",
      "         0.2063, 0.2192, 0.2063, 0.2063, 0.2063, 0.2063, 0.2192, 0.2063, 0.2192,\n",
      "         0.2192, 0.2063, 0.2063, 0.2192, 0.2192, 0.2063, 0.2063, 0.2063, 0.2063,\n",
      "         0.2063, 0.2192, 0.2192, 0.2192, 0.2063, 0.2063, 0.2063, 0.2192, 0.2063,\n",
      "         0.2063, 0.2192, 0.2192, 0.2192, 0.2063, 0.2063, 0.2063, 0.2192, 0.2063,\n",
      "         0.2063, 0.2063, 0.2063, 0.2063, 0.2192, 0.2192, 0.2063, 0.2063, 0.2063,\n",
      "         0.2192, 0.2063, 0.2192, 0.2192, 0.2192, 0.2063, 0.2192, 0.2192, 0.2063,\n",
      "         0.2063, 0.2063, 0.2192, 0.2063, 0.2063, 0.2192, 0.2192, 0.2192, 0.2063,\n",
      "         0.2192, 0.2192, 0.2192, 0.2192, 0.2063, 0.2063, 0.2063, 0.2063, 0.2192,\n",
      "         0.2063, 0.2063, 0.2063, 0.2192, 0.2192, 0.2063, 0.2063, 0.2063, 0.2192,\n",
      "         0.2192, 0.2063, 0.2063, 0.2063, 0.2063, 0.2063, 0.2063, 0.2192, 0.2063,\n",
      "         0.2063, 0.0220, 0.2192, 0.2063, 0.2063, 0.2192, 0.2063, 0.2063, 0.2063,\n",
      "         0.2063, 0.2063, 0.2063, 0.2063, 0.2192, 0.2192, 0.2192, 0.2063, 0.2063,\n",
      "         0.2063, 0.2192, 0.2192, 0.2192, 0.2063, 0.2063, 0.2063, 0.2192, 0.2063,\n",
      "         0.2063, 0.2063, 0.2063, 0.2063, 0.2063, 0.2192, 0.2063, 0.2063, 0.2063,\n",
      "         0.2192, 0.2063, 0.2192, 0.2192, 0.2063, 0.2063, 0.2063, 0.2192, 0.2063,\n",
      "         0.2192, 0.2063, 0.2063, 0.2063, 0.2192, 0.2063, 0.2192, 0.2063, 0.2063,\n",
      "         0.2063, 0.2063, 0.2192, 0.2063, 0.2063, 0.2063, 0.2192, 0.2063, 0.2192,\n",
      "         0.2192, 0.2192, 0.2063, 0.2192, 0.0220, 0.2192, 0.2063, 0.2063, 0.2063,\n",
      "         0.2192, 0.2063, 0.2192, 0.2063, 0.2063, 0.2063, 0.2063, 0.2192, 0.2192,\n",
      "         0.2192, 0.2192, 0.2192, 0.2063, 0.2063, 0.2063, 0.2063, 0.2192, 0.2192,\n",
      "         0.2063, 0.2063, 0.2063, 0.2192, 0.2063, 0.2063, 0.2063, 0.2192, 0.2063,\n",
      "         0.2192, 0.2063, 0.0727, 0.2192, 0.2063, 0.2192, 0.2063, 0.2192, 0.2063,\n",
      "         0.2063, 0.2192, 0.2063, 0.2063, 0.2063, 0.2063, 0.2192, 0.2063, 0.2063,\n",
      "         0.2063, 0.2192, 0.2192, 0.2192, 0.2063, 0.2063, 0.2063, 0.2063, 0.2063,\n",
      "         0.2192, 0.2192, 0.2063, 0.2063, 0.2192, 0.2063, 0.2063, 0.2192, 0.2192,\n",
      "         0.2063, 0.2063, 0.2063, 0.2192, 0.2063, 0.2192, 0.2063, 0.2063, 0.2192,\n",
      "         0.2192, 0.2063, 0.2063, 0.2192, 0.2063, 0.2063, 0.2063, 0.2192, 0.2192,\n",
      "         0.2063, 0.2063, 0.2063, 0.2063, 0.2063, 0.2063, 0.2192, 0.2192, 0.2192,\n",
      "         0.2063, 0.2063, 0.2063, 0.2192, 0.2063, 0.2063, 0.2192, 0.2063, 0.2192,\n",
      "         0.2063, 0.2063, 0.2063, 0.2063, 0.2192, 0.2063, 0.2192, 0.2063, 0.2063,\n",
      "         0.2063, 0.2192, 0.2063, 0.2192, 0.2192, 0.2192, 0.2063, 0.2063, 0.2192,\n",
      "         0.2192, 0.2063, 0.2063, 0.2192, 0.2063, 0.2192, 0.2063, 0.2063, 0.2192,\n",
      "         0.2063, 0.2063, 0.2192, 0.2063, 0.2192, 0.2063, 0.2192, 0.2192, 0.2063,\n",
      "         0.2192, 0.2063, 0.2063, 0.2063, 0.2063, 0.2063, 0.2063, 0.2192, 0.2063,\n",
      "         0.2063, 0.2192, 0.2063, 0.2063, 0.0727, 0.2192, 0.2063, 0.2063, 0.2063,\n",
      "         0.2063, 0.2063, 0.2063, 0.2063, 0.2063, 0.2192, 0.2063, 0.2063, 0.2063,\n",
      "         0.2063, 0.2192, 0.2063, 0.2192, 0.2063, 0.2192, 0.2063, 0.2063, 0.2063,\n",
      "         0.2063, 0.2063, 0.2192, 0.2063, 0.2063, 0.2192, 0.2063, 0.2063, 0.2063,\n",
      "         0.2063, 0.2063, 0.2192, 0.2063, 0.2063, 0.2063, 0.2192, 0.2192, 0.2192,\n",
      "         0.2063, 0.2063, 0.2192, 0.2063, 0.2063, 0.2192, 0.2063, 0.2063, 0.2063,\n",
      "         0.2063, 0.2192, 0.2063, 0.2063, 0.2063, 0.2192, 0.2063, 0.2192, 0.2063,\n",
      "         0.2063, 0.2063, 0.2063, 0.2192, 0.2063, 0.2192, 0.2063, 0.2063, 0.2063,\n",
      "         0.2063, 0.2192, 0.2192, 0.2063, 0.2063, 0.2192, 0.2192, 0.2192, 0.2063,\n",
      "         0.2192, 0.2192, 0.2063, 0.2192, 0.2192, 0.2063, 0.2192, 0.2192, 0.2063,\n",
      "         0.2063, 0.2192, 0.2063, 0.2063, 0.2063, 0.2063, 0.2192, 0.2063, 0.2192,\n",
      "         0.2063, 0.2192, 0.2192, 0.2063, 0.2063, 0.2192, 0.2192, 0.2192, 0.2063,\n",
      "         0.2063, 0.2063, 0.2192, 0.2063, 0.2063, 0.2063, 0.2063, 0.2192, 0.2063,\n",
      "         0.2063, 0.2063, 0.2063, 0.2063, 0.2063, 0.2192, 0.2063, 0.2063, 0.2063,\n",
      "         0.2063, 0.2063, 0.2063, 0.2192, 0.2192, 0.2063, 0.2063, 0.2192, 0.2192,\n",
      "         0.2063, 0.2063, 0.2192, 0.2063, 0.0727, 0.2192, 0.2063, 0.2063, 0.2063,\n",
      "         0.2192, 0.2192, 0.2063, 0.0220, 0.2192, 0.2063, 0.2063, 0.2192, 0.2063,\n",
      "         0.2192, 0.2063, 0.2192, 0.2063, 0.2063, 0.2192, 0.2063, 0.2063, 0.2063,\n",
      "         0.2192, 0.2192, 0.2063, 0.2063, 0.2063, 0.2063, 0.2192, 0.2192, 0.2063,\n",
      "         0.2063, 0.2063, 0.2063, 0.2063, 0.2192, 0.2192, 0.2063, 0.2063, 0.2063,\n",
      "         0.2063, 0.2063, 0.2063, 0.2192, 0.2192, 0.2192, 0.2192, 0.2192, 0.2063,\n",
      "         0.2063, 0.2063, 0.2192, 0.2063, 0.2063, 0.2192, 0.2192, 0.2063, 0.2063,\n",
      "         0.2063, 0.2063, 0.2063, 0.2192, 0.2063, 0.2192, 0.2192, 0.2063, 0.2063,\n",
      "         0.2192, 0.2063, 0.2192, 0.2063, 0.2063, 0.2063, 0.2063, 0.2063, 0.2063,\n",
      "         0.2192, 0.2063, 0.2192, 0.2063, 0.2192, 0.2063, 0.2192, 0.2192, 0.2063,\n",
      "         0.2063, 0.2192, 0.2063, 0.0220, 0.2063, 0.2063, 0.2063, 0.2063, 0.2192,\n",
      "         0.2063, 0.2192, 0.2192]]) torch.Size([1, 768])\n",
      "Веса до кластеризации\n",
      "[[-0.02353618 -0.02100843  0.00230313 ...  0.03422362  0.01323184\n",
      "  -0.03111955]\n",
      " [ 0.00248587  0.01289506  0.00422699 ...  0.00634617  0.02428462\n",
      "   0.0159643 ]]\n",
      "\n",
      "Веса после кластеризации\n",
      "tensor([[-0.0323, -0.0323,  0.0117,  ...,  0.0347,  0.0117, -0.0323],\n",
      "        [ 0.0117,  0.0117,  0.0117,  ...,  0.0117,  0.0347,  0.0117]]) torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\NEW_MACHINE\\Programs\\Anaconda\\envs\\Model_Compression\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "apply_weight_clusterization(parameters_to_clusterization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5fd285f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 327.302MB\n"
     ]
    }
   ],
   "source": [
    "# Найдем размер модели после прунинга.\n",
    "size_measurement(vit_model_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "19199fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0323, -0.0323,  0.0117,  ...,  0.0347,  0.0117, -0.0323],\n",
      "        [ 0.0117,  0.0117,  0.0117,  ...,  0.0117,  0.0347,  0.0117]])\n"
     ]
    }
   ],
   "source": [
    "# Видим, что кластеризация задействована, веса одинаковые.\n",
    "print(vit_model_copy.classifier.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "1ba0e8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели после кластеризации весов =  0.96875\n",
      "Время обработки изображений модели после кластеризации весов =  924.4877910614014  секунд\n",
      "Скорость обработки изображений у модели после кластеризации весов составила   0.17306880798967017  картинок в секунду\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Собака 1, кошка 0.\n",
    "target_list = []\n",
    "predict_list = []\n",
    "\n",
    "for element in images_list:\n",
    "\n",
    "    image = Image.open(path + element, mode='r', formats=None)\n",
    "\n",
    "    inputs = extractor(image, return_tensors=\"pt\")\n",
    "    predict = model_use(vit_model_copy, inputs)\n",
    "    target = element[:element.find(\".\")]\n",
    "\n",
    "    if target == \"dog\":\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 0\n",
    "\n",
    "    target_list.append(label)\n",
    "\n",
    "    if predict == \"dogs\":\n",
    "        pr = 1\n",
    "    else:\n",
    "        pr = 0\n",
    "\n",
    "    predict_list.append(pr)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "acc = accuracy_score(target_list, predict_list)\n",
    "print(\"Точность модели после кластеризации весов = \", acc)\n",
    "print(\"Время обработки изображений модели после кластеризации весов = \", end_time-start_time, \" секунд\")\n",
    "print(\"Скорость обработки изображений у модели после кластеризации весов составила  \", len(images_list)/(end_time-start_time), \" картинок в секунду\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e427d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
