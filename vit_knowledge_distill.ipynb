{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "_VGZX493gSvp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VGZX493gSvp",
        "outputId": "9ad5e1eb-88e2-48af-905f-da154c71ae6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ec6kMkWuh4LB",
      "metadata": {
        "id": "ec6kMkWuh4LB"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets transformers[torch] accelerate>=0.20.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "F1tOd1EnPUdG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1tOd1EnPUdG",
        "outputId": "38c78557-383f-4beb-b17d-4f4ff178580f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy исходной модели=  0.9625\n",
            "Время обработки изображений исходной модели=  194.9379551410675  секунд\n",
            "Скорость обработки изображений у исходной модели составила   0.8207739733609879  картинок в секунду\n",
            "Avg inference time: 1218.3622 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "from transformers import AutoFeatureExtractor, AutoModelForImageClassification\n",
        "from PIL import Image\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "path_to_model = '/content/drive/MyDrive/model_compression/my_model'\n",
        "processor = AutoFeatureExtractor.from_pretrained(path_to_model)\n",
        "vit_model = AutoModelForImageClassification.from_pretrained(path_to_model)\n",
        "\n",
        "def model_use(model, img):\n",
        "    with torch.no_grad():\n",
        "        logits = model(**img).logits\n",
        "    pred_label = logits.argmax(-1).item()\n",
        "    return model.config.id2label[pred_label]\n",
        "\n",
        "images_list = os.listdir('/content/drive/MyDrive/model_compression/data')\n",
        "\n",
        "start = time.time()\n",
        "target_lst = []\n",
        "predict_lst = []\n",
        "logits_lst = []\n",
        "\n",
        "for img_name in images_list:\n",
        "    img_path = os.path.join('/content/drive/MyDrive/model_compression/data', img_name)\n",
        "    image = Image.open(img_path, mode='r')\n",
        "    inputs = processor(image, return_tensors=\"pt\")\n",
        "    predicts, logits = model_use(vit_model, inputs)\n",
        "    target = img_name[:img_name.find(\".\")]\n",
        "    if target == \"dog\":\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "    target_lst.append(label)\n",
        "    if predicts == \"dog\":\n",
        "        pr = 1\n",
        "    else:\n",
        "        pr = 0\n",
        "    predict_lst.append(pr)\n",
        "    logits_lst.append(logits)\n",
        "\n",
        "end = time.time()\n",
        "acc = accuracy_score(target_lst, predict_lst)\n",
        "\n",
        "print(\"accuracy исходной модели= \", acc)\n",
        "print(\"Время обработки изображений исходной модели= \", end-start, \" секунд\")\n",
        "print(\"Скорость обработки изображений у исходной модели составила  \", len(images_list)/(end-start), \" картинок в секунду\")\n",
        "infer_time = ((end - start) / len(images_list)) * 1000\n",
        "print(f'Avg inference time: {infer_time:.4f} ms')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "7Umd7GxhS044",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Umd7GxhS044",
        "outputId": "0590a387-e430-4d2e-e714-adafed4d71f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2919: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20, Loss: 1.422323614358902\n",
            "Epoch 2/20, Loss: 0.3584473133087158\n",
            "Epoch 3/20, Loss: 0.37765002250671387\n",
            "Epoch 4/20, Loss: 0.2627972811460495\n",
            "Epoch 5/20, Loss: 0.2615549564361572\n",
            "Epoch 6/20, Loss: 0.25926532596349716\n",
            "Epoch 7/20, Loss: 0.2586737275123596\n",
            "Epoch 8/20, Loss: 0.25841058790683746\n",
            "Epoch 9/20, Loss: 0.25850844383239746\n",
            "Epoch 10/20, Loss: 0.258448526263237\n",
            "Epoch 11/20, Loss: 0.2582792341709137\n",
            "Epoch 12/20, Loss: 0.25835975259542465\n",
            "Epoch 13/20, Loss: 0.2582198232412338\n",
            "Epoch 14/20, Loss: 0.25832997262477875\n",
            "Epoch 15/20, Loss: 0.25821061432361603\n",
            "Epoch 16/20, Loss: 0.25827697664499283\n",
            "Epoch 17/20, Loss: 0.25821562111377716\n",
            "Epoch 18/20, Loss: 0.25824691355228424\n",
            "Epoch 19/20, Loss: 0.2582192122936249\n",
            "Epoch 20/20, Loss: 0.25822728127241135\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Cчитаем soft labels с температурой T.\n",
        "Более высокая температура приводит к более \"мягким\" меткам,\n",
        "которые имеют большую разницу между вероятностями классов.\n",
        "\n",
        "T = 2.0 - Умеренно \"мягкие\" метки.\n",
        "\n",
        "'''\n",
        "T = 2.0\n",
        "soft_labels = F.softmax(torch.cat(logits_lst, dim=0) / T, dim=1)\n",
        "\n",
        "# Наша слабая модель (пример с ResNet-18)\n",
        "student_model = models.resnet18(pretrained=False)\n",
        "student_model.fc = nn.Linear(student_model.fc.in_features, 2)  # 2 класса: cat и dog\n",
        "\n",
        "# Loss с учетом Knowledge Distillation\n",
        "def distillation_loss(outputs_student, outputs_teacher, alpha=0.5, temperature=1.0):\n",
        "    hard_loss = F.cross_entropy(outputs_student, outputs_teacher.argmax(-1))\n",
        "    soft_loss = nn.KLDivLoss()(F.log_softmax(outputs_student / temperature, dim=1),\n",
        "                               F.softmax(outputs_teacher / temperature, dim=1))\n",
        "    return (1 - alpha) * hard_loss + alpha * temperature**2 * soft_loss\n",
        "\n",
        "# еще и шедулер добавим\n",
        "optimizer = optim.Adam(student_model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "\n",
        "# Учим студента\n",
        "num_epochs = 20\n",
        "\n",
        "student_model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for img_name, soft_label in zip(images_list, soft_labels):\n",
        "        img_path = os.path.join('/content/drive/MyDrive/model_compression/data', img_name)\n",
        "        image = Image.open(img_path, mode='r')\n",
        "\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "        image = transform(image)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs_student = student_model(image.unsqueeze(0)) # добавим измерение батча\n",
        "        outputs_teacher = soft_label.unsqueeze(0)  # тензор с размером батча 1\n",
        "\n",
        "        loss = distillation_loss(outputs_student, outputs_teacher)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss}')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "8nYRnGP5ZslJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nYRnGP5ZslJ",
        "outputId": "05ebcc56-6436-4e38-926e-5a92743851a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy студента=  0.5\n",
            "Время обработки изображений студентской моделью=  30.631128072738647  секунд\n",
            "Скорость обработки изображений у студентской модели составила   5.223444582911008  картинок в секунду\n",
            "Avg inference time: 191.4446 ms\n"
          ]
        }
      ],
      "source": [
        "# Оценка студента\n",
        "student_model.eval()\n",
        "student_preds = []\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "for img_name in images_list:\n",
        "    img_path = os.path.join('/content/drive/MyDrive/model_compression/data', img_name)\n",
        "    image = Image.open(img_path, mode='r')\n",
        "\n",
        "    image = transform(image)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = student_model(image.unsqueeze(0))\n",
        "    pred_label = logits.argmax(-1).item()\n",
        "    student_preds.append(pred_label)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "student_acc = accuracy_score(target_lst, student_preds)\n",
        "\n",
        "print(\"Accuracy студента= \", student_acc)\n",
        "print(\"Время обработки изображений студентской моделью= \", end-start, \" секунд\")\n",
        "print(\"Скорость обработки изображений у студентской модели составила  \", len(images_list)/(end-start), \" картинок в секунду\")\n",
        "\n",
        "infer_time = ((end - start) / len(images_list)) * 1000\n",
        "print(f'Avg inference time: {infer_time:.4f} ms')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
