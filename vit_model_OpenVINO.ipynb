{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04a583d2-6399-47d9-9d5a-f3187b299aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from transformers import AutoFeatureExtractor, AutoModelForImageClassification, ViTImageProcessor\n",
    "import torch\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy\n",
    "from openvino.tools.mo import convert_model\n",
    "import openvino as ov\n",
    "import numpy as np\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d43f23f-ac35-4050-ab6b-405a9389fb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь к нашему ViT, который будем конвертировать.\n",
    "path_to_model = \"weights/my_model\"\n",
    "\n",
    "extractor = ViTImageProcessor.from_pretrained(path_to_model)\n",
    "vit_model = AutoModelForImageClassification.from_pretrained(path_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e33c3f12-d0c4-4d78-b4e6-91952684abeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_use(model, img):\n",
    "    with torch.no_grad():\n",
    "        logits = model(**img).logits\n",
    "\n",
    "    predicted_label = logits.argmax(-1).item()\n",
    "\n",
    "    return model.config.id2label[predicted_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e462bc3-9fa5-4d7f-965d-aeb2cae47b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь к тестовым картинкам.\n",
    "path_to_images = \"data/\"\n",
    "images_list = os.listdir(path_to_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "935ccbd5-cd3e-43af-b843-8b56710f8dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для замера размера модели.\n",
    "def size_measurement(model):\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "    size_all_mb = (param_size + buffer_size) / (1024 ** 2)\n",
    "    print('model size: {:.3f}MB'.format(size_all_mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8359afc7-2598-47f6-8691-1dec1b512aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 327.302MB\n"
     ]
    }
   ],
   "source": [
    "# Найдем исходный размер модели.\n",
    "size_measurement(vit_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd63532a-b6c9-4fc6-8a32-5fae59a59624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/ssaraev/.conda/envs/compession/lib/python3.10/site-packages/transformers/models/vit/modeling_vit.py:170: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if num_channels != self.num_channels:\n",
      "/mnt/disk1/ssaraev/.conda/envs/compession/lib/python3.10/site-packages/transformers/models/vit/modeling_vit.py:176: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if height != self.image_size[0] or width != self.image_size[1]:\n",
      "/mnt/disk1/ssaraev/.conda/envs/compession/lib/python3.10/site-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ov_model = convert_model(vit_model,  example_input=torch.randn(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e29697a-757c-4fdc-b695-5f0749591786",
   "metadata": {},
   "outputs": [],
   "source": [
    "core = ov.Core()\n",
    "compiled_model = core.compile_model(ov_model, \"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd176a13-3be0-4db5-b56e-81082bb258be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postprocessing function for getting results in the same way for both PyTorch model inference and OpenVINO\n",
    "def postprocess_result(output_tensor:np.ndarray, top_k:int = 5):\n",
    "    \"\"\"\n",
    "    Posprocess model results. This function applied sofrmax on output tensor and returns specified top_k number of labels with highest probability\n",
    "    Parameters:\n",
    "      output_tensor (np.ndarray): model output tensor with probabilities\n",
    "      top_k (int, *optional*, default 5): number of labels with highest probability for return\n",
    "    Returns:\n",
    "      topk_labels: label ids for selected top_k scores\n",
    "      topk_scores: selected top_k highest scores predicted by model\n",
    "    \"\"\"\n",
    "    softmaxed_scores = softmax(output_tensor, -1)[0]\n",
    "    topk_labels = np.argsort(softmaxed_scores)[-top_k:][::-1]\n",
    "    topk_scores = softmaxed_scores[topk_labels]\n",
    "    return topk_labels, topk_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ceb2d83d-0565-4625-8f7d-c7c9cb6571d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность сконвертированной в OpenVINO модели=  0.9875\n",
      "Время обработки изображений сконвертированной в OpenVINO моделью =  7.952617883682251  секунд\n",
      "Скорость обработки изображений у сконвертированной в OpenVINO модели составила   20.11916105365749  картинок в секунду\n"
     ]
    }
   ],
   "source": [
    "# Запустим тест нашей OpenVINO модели.\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Собака 1, кошка 0.\n",
    "target_list = []\n",
    "predict_list = []\n",
    "\n",
    "for element in images_list:\n",
    "\n",
    "    image = Image.open(path_to_images + element, mode='r', formats=None)\n",
    "\n",
    "    inputs = extractor(image, return_tensors=\"pt\")[\"pixel_values\"]\n",
    "    result = compiled_model(inputs)[0]\n",
    "    predict, score = postprocess_result(result, top_k=1)\n",
    "    target = element[:element.find(\".\")]\n",
    "\n",
    "    if target == \"dog\":\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 0\n",
    "\n",
    "    target_list.append(label)\n",
    "    predict_list.append(predict[0])\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "acc = accuracy_score(target_list, predict_list)\n",
    "# Postprocess results\n",
    "\n",
    "print(\"Точность сконвертированной в OpenVINO модели= \", acc)\n",
    "print(\"Время обработки изображений сконвертированной в OpenVINO моделью = \", end_time-start_time, \" секунд\")\n",
    "print(\"Скорость обработки изображений у сконвертированной в OpenVINO модели составила  \", len(images_list)/(end_time-start_time), \" картинок в секунду\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0585a833-a9e1-4e07-b75a-e5d5eb0013e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ov.save_model(ov_model, \"openvino.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61f1fb7-9c72-4357-a087-a21be6dfa140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
